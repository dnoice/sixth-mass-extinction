{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "✒ Metadata\n",
    "    - Title: {Notebook Title} (SME Episode {X.X} - v1.0)\n",
    "    - File Name: {NN}-{notebook-name}.ipynb\n",
    "    - Relative Path: research-stacks/{X.0}-{section}/{X.X}-{episode}/notebooks/{NN}-{notebook-name}.ipynb\n",
    "    - Artifact Type: notebook\n",
    "    - Version: 1.0.0\n",
    "    - Date: {YYYY-MM-DD}\n",
    "    - Update: {Day, Month DD, YYYY}\n",
    "    - Author: Dennis 'dnoice' Smaltz\n",
    "    - A.I. Acknowledgement: Anthropic - Claude Opus 4.5\n",
    "    - Signature: ︻デ═─── ✦ ✦ ✦ | Aim Twice, Shoot Once!\n",
    "\n",
    "✒ Description:\n",
    "    {Brief description of the notebook's purpose and what analysis it performs.\n",
    "    How does this notebook contribute to the episode's overall analysis?}\n",
    "\n",
    "✒ Key Features:\n",
    "    - Feature 1: {Description}\n",
    "    - Feature 2: {Description}\n",
    "    - Feature 3: {Description}\n",
    "    - Feature 4: {Description}\n",
    "    - Feature 5: {Description}\n",
    "\n",
    "✒ Usage Instructions:\n",
    "    Run cells sequentially after activating the project virtual environment.\n",
    "    Ensure data files are present in ../data/raw/ before execution.\n",
    "\n",
    "✒ Other Important Information:\n",
    "    - Dependencies: pandas, numpy, matplotlib, seaborn, plotly\n",
    "    - Input Data: ../data/raw/{source_files}\n",
    "    - Output Data: ../data/processed/{output_files}\n",
    "    - Output Figures: ../visualizations/figures/{figure_files}\n",
    "    - Related Notebooks: {list related notebooks}\n",
    "    - Article Section: {which article sections this supports}\n",
    "---------\n",
    "-->\n",
    "\n",
    "# Episode {X.X}: {Episode Title}\n",
    "\n",
    "## Notebook {NN}: {Notebook Purpose}\n",
    "\n",
    "> **Series:** Sixth Mass Extinction | **Section:** {X.0} - {Section Name} | **Episode:** {X.X}\n",
    ">\n",
    "> **Article:** [ARTICLE_{X.X}.md](../article/ARTICLE_{X.X}.md) | **Data:** [MANIFEST.md](../data/metadata/MANIFEST.md)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Setup & Configuration](#1-setup--configuration)\n",
    "2. [Data Acquisition](#2-data-acquisition)\n",
    "3. [Data Processing](#3-data-processing)\n",
    "4. [Exploratory Analysis](#4-exploratory-analysis)\n",
    "5. [Statistical Analysis](#5-statistical-analysis)\n",
    "6. [Visualizations](#6-visualizations)\n",
    "7. [Key Findings](#7-key-findings)\n",
    "8. [Export & Documentation](#8-export--documentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STANDARD IMPORTS\n",
    "# =============================================================================\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Statistics\n",
    "from scipy import stats\n",
    "\n",
    "# Utilities\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Episode metadata\n",
    "EPISODE = '{X.X}'\n",
    "EPISODE_NAME = '{Episode Name}'\n",
    "SECTION = '{X.0}'\n",
    "SECTION_NAME = '{Section Name}'\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = Path('../../../..')\n",
    "EPISODE_ROOT = Path('..')\n",
    "\n",
    "DATA_RAW = EPISODE_ROOT / 'data' / 'raw'\n",
    "DATA_PROCESSED = EPISODE_ROOT / 'data' / 'processed'\n",
    "DATA_METADATA = EPISODE_ROOT / 'data' / 'metadata'\n",
    "\n",
    "VIZ_FIGURES = EPISODE_ROOT / 'visualizations' / 'figures'\n",
    "VIZ_INTERACTIVE = EPISODE_ROOT / 'visualizations' / 'interactive'\n",
    "VIZ_EXPORTS = EPISODE_ROOT / 'visualizations' / 'exports'\n",
    "\n",
    "# Ensure directories exist\n",
    "for path in [DATA_RAW, DATA_PROCESSED, DATA_METADATA, VIZ_FIGURES, VIZ_INTERACTIVE, VIZ_EXPORTS]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# =============================================================================\n",
    "# SME STYLE CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Load SME color palette\n",
    "import sys\n",
    "sys.path.insert(0, str(PROJECT_ROOT / 'research-stacks' / '_shared' / 'styles'))\n",
    "try:\n",
    "    from color_palettes import *\n",
    "    print('SME color palette loaded')\n",
    "except ImportError:\n",
    "    print('Warning: SME color palette not found, using defaults')\n",
    "    CRISIS_RED = '#d32f2f'\n",
    "    DATA_BLUE = '#1976d2'\n",
    "    HOPE_GREEN = '#388e3c'\n",
    "\n",
    "# Matplotlib configuration\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': (12, 6),\n",
    "    'figure.dpi': 100,\n",
    "    'font.size': 12,\n",
    "    'axes.titlesize': 14,\n",
    "    'axes.titleweight': 'bold',\n",
    "    'axes.labelsize': 12,\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.right': False,\n",
    "    'savefig.dpi': 300,\n",
    "    'savefig.bbox': 'tight'\n",
    "})\n",
    "\n",
    "print(f'\\n{\"=\"*60}')\n",
    "print(f'SME Episode {EPISODE}: {EPISODE_NAME}')\n",
    "print(f'Section {SECTION}: {SECTION_NAME}')\n",
    "print(f'{\"=\"*60}')\n",
    "print(f'Setup complete - {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Data Acquisition\n",
    "\n",
    "### 2.1 Data Source Overview\n",
    "\n",
    "| Source | Type | Tier | File | Description |\n",
    "|--------|------|------|------|-------------|\n",
    "| {Source 1} | {Type} | {1-4} | `{filename}` | {Description} |\n",
    "| {Source 2} | {Type} | {1-4} | `{filename}` | {Description} |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOAD RAW DATA\n",
    "# =============================================================================\n",
    "\n",
    "# Primary dataset\n",
    "# df_raw = pd.read_csv(DATA_RAW / 'primary_data.csv')\n",
    "\n",
    "# Secondary dataset (if applicable)\n",
    "# df_secondary = pd.read_csv(DATA_RAW / 'secondary_data.csv')\n",
    "\n",
    "# Display data info\n",
    "# print(f'Primary dataset shape: {df_raw.shape}')\n",
    "# print(f'Columns: {list(df_raw.columns)}')\n",
    "# df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA QUALITY CHECK\n",
    "# =============================================================================\n",
    "\n",
    "# def data_quality_report(df, name='Dataset'):\n",
    "#     \"\"\"Generate data quality report.\"\"\"\n",
    "#     print(f'\\n{\"=\"*60}')\n",
    "#     print(f'Data Quality Report: {name}')\n",
    "#     print(f'{\"=\"*60}')\n",
    "#     print(f'Shape: {df.shape[0]} rows × {df.shape[1]} columns')\n",
    "#     print(f'\\nMissing Values:')\n",
    "#     missing = df.isnull().sum()\n",
    "#     missing_pct = (missing / len(df)) * 100\n",
    "#     for col in df.columns:\n",
    "#         if missing[col] > 0:\n",
    "#             print(f'  {col}: {missing[col]} ({missing_pct[col]:.1f}%)')\n",
    "#     print(f'\\nData Types:')\n",
    "#     print(df.dtypes)\n",
    "#     return df.describe()\n",
    "\n",
    "# data_quality_report(df_raw, 'Primary Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Data Processing\n",
    "\n",
    "### 3.1 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA CLEANING\n",
    "# =============================================================================\n",
    "\n",
    "# Create working copy\n",
    "# df = df_raw.copy()\n",
    "\n",
    "# Handle missing values\n",
    "# df = df.dropna(subset=['required_column'])\n",
    "# df['optional_column'] = df['optional_column'].fillna(0)\n",
    "\n",
    "# Remove duplicates\n",
    "# df = df.drop_duplicates()\n",
    "\n",
    "# Type conversions\n",
    "# df['date'] = pd.to_datetime(df['date'])\n",
    "# df['category'] = df['category'].astype('category')\n",
    "\n",
    "# print(f'After cleaning: {df.shape[0]} rows ({len(df_raw) - len(df)} removed)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FEATURE ENGINEERING\n",
    "# =============================================================================\n",
    "\n",
    "# Temporal features\n",
    "# df['year'] = df['date'].dt.year\n",
    "# df['decade'] = (df['year'] // 10) * 10\n",
    "\n",
    "# Calculated metrics\n",
    "# df['rate'] = df['count'] / df['total'] * 100\n",
    "\n",
    "# Categorical encoding\n",
    "# df['region_code'] = df['region'].map({'North': 1, 'South': 2, 'East': 3, 'West': 4})\n",
    "\n",
    "# Aggregations\n",
    "# df_grouped = df.groupby(['year', 'category']).agg({\n",
    "#     'value': ['sum', 'mean', 'count']\n",
    "# }).reset_index()\n",
    "\n",
    "# print(f'Features added: {list(df.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SAVE PROCESSED DATA\n",
    "# =============================================================================\n",
    "\n",
    "# Save main processed dataset\n",
    "# df.to_csv(DATA_PROCESSED / f'{EPISODE}_processed.csv', index=False)\n",
    "# print(f'Saved: {DATA_PROCESSED / f\"{EPISODE}_processed.csv\"}')\n",
    "\n",
    "# Save aggregated dataset\n",
    "# df_grouped.to_csv(DATA_PROCESSED / f'{EPISODE}_aggregated.csv', index=False)\n",
    "# print(f'Saved: {DATA_PROCESSED / f\"{EPISODE}_aggregated.csv\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Exploratory Analysis\n",
    "\n",
    "### 4.1 Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SUMMARY STATISTICS\n",
    "# =============================================================================\n",
    "\n",
    "# Descriptive statistics\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# KEY METRICS CALCULATION\n",
    "# =============================================================================\n",
    "\n",
    "# Example: Calculate E/MSY (extinctions per million species-years)\n",
    "# def calculate_e_msy(extinctions, species_count, years):\n",
    "#     \"\"\"Calculate extinction rate in E/MSY.\"\"\"\n",
    "#     species_years = species_count * years\n",
    "#     return extinctions / species_years * 1_000_000\n",
    "\n",
    "# e_msy = calculate_e_msy(\n",
    "#     extinctions=df['extinctions'].sum(),\n",
    "#     species_count=df['species'].nunique(),\n",
    "#     years=df['year'].nunique()\n",
    "# )\n",
    "# print(f'E/MSY: {e_msy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DISTRIBUTION PLOTS\n",
    "# =============================================================================\n",
    "\n",
    "# fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Histogram\n",
    "# axes[0].hist(df['value'], bins=30, color=DATA_BLUE, edgecolor='white')\n",
    "# axes[0].set_title('Distribution of Values')\n",
    "# axes[0].set_xlabel('Value')\n",
    "# axes[0].set_ylabel('Frequency')\n",
    "\n",
    "# Box plot\n",
    "# sns.boxplot(data=df, y='value', ax=axes[1], color=DATA_BLUE)\n",
    "# axes[1].set_title('Value Distribution')\n",
    "\n",
    "# QQ plot\n",
    "# stats.probplot(df['value'], dist='norm', plot=axes[2])\n",
    "# axes[2].set_title('Q-Q Plot')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Statistical Analysis\n",
    "\n",
    "### 5.1 Trend Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TREND ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "# def calculate_trend(x, y):\n",
    "#     \"\"\"Calculate linear trend with statistics.\"\"\"\n",
    "#     slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "#     return {\n",
    "#         'slope': slope,\n",
    "#         'intercept': intercept,\n",
    "#         'r_squared': r_value**2,\n",
    "#         'p_value': p_value,\n",
    "#         'std_err': std_err\n",
    "#     }\n",
    "\n",
    "# trend = calculate_trend(df['year'], df['value'])\n",
    "# print(f'Trend Analysis:')\n",
    "# print(f'  Slope: {trend[\"slope\"]:.4f} per year')\n",
    "# print(f'  R²: {trend[\"r_squared\"]:.4f}')\n",
    "# print(f'  P-value: {trend[\"p_value\"]:.4e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CORRELATION ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "# Calculate correlation matrix\n",
    "# numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "# corr_matrix = df[numeric_cols].corr()\n",
    "\n",
    "# Visualize\n",
    "# fig, ax = plt.subplots(figsize=(10, 8))\n",
    "# sns.heatmap(corr_matrix, annot=True, cmap='RdBu_r', center=0, ax=ax)\n",
    "# ax.set_title('Correlation Matrix')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Visualizations\n",
    "\n",
    "### 6.1 Figure 1: {Primary Visualization Title}\n",
    "\n",
    "**Purpose:** {What this figure shows and why it matters}\n",
    "\n",
    "**Article Section:** {Which section of the article this supports}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FIGURE 1: {TITLE}\n",
    "# =============================================================================\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Main plot\n",
    "# ax.plot(df['year'], df['value'], color=CRISIS_RED, linewidth=2, label='Observed')\n",
    "\n",
    "# Trend line\n",
    "# x_trend = np.array(df['year'])\n",
    "# y_trend = trend['slope'] * x_trend + trend['intercept']\n",
    "# ax.plot(x_trend, y_trend, '--', color='gray', linewidth=1.5, label='Trend')\n",
    "\n",
    "# Labels and formatting\n",
    "# ax.set_title('Figure 1: {Title}', fontsize=14, fontweight='bold')\n",
    "# ax.set_xlabel('Year')\n",
    "# ax.set_ylabel('Value')\n",
    "# ax.legend(loc='upper left')\n",
    "# ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Save\n",
    "# fig.savefig(VIZ_FIGURES / 'fig01-{name}.png', dpi=300, bbox_inches='tight')\n",
    "# fig.savefig(VIZ_EXPORTS / 'fig01-{name}.png', dpi=300, bbox_inches='tight')\n",
    "# plt.show()\n",
    "# print(f'Saved: fig01-{name}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Figure 2: {Secondary Visualization Title}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FIGURE 2: {TITLE}\n",
    "# =============================================================================\n",
    "\n",
    "# {Visualization code}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Interactive Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# INTERACTIVE VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "# fig = px.line(\n",
    "#     df, \n",
    "#     x='year', \n",
    "#     y='value',\n",
    "#     title=f'Episode {EPISODE}: {EPISODE_NAME}',\n",
    "#     labels={'year': 'Year', 'value': 'Value'},\n",
    "#     color_discrete_sequence=[CRISIS_RED]\n",
    "# )\n",
    "\n",
    "# fig.update_layout(\n",
    "#     template='plotly_white',\n",
    "#     hovermode='x unified'\n",
    "# )\n",
    "\n",
    "# fig.write_html(VIZ_INTERACTIVE / f'{EPISODE}_interactive.html')\n",
    "# fig.show()\n",
    "# print(f'Saved: {EPISODE}_interactive.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Key Findings\n",
    "\n",
    "### 7.1 Summary Statistics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# KEY FINDINGS SUMMARY\n",
    "# =============================================================================\n",
    "\n",
    "# findings = {\n",
    "#     'Episode': EPISODE,\n",
    "#     'Episode Name': EPISODE_NAME,\n",
    "#     'Analysis Date': datetime.now().strftime('%Y-%m-%d'),\n",
    "#     'Sample Size': len(df),\n",
    "#     'Time Period': f\"{df['year'].min()}-{df['year'].max()}\",\n",
    "#     'Primary Metric': '{value}',\n",
    "#     'Trend (per year)': f\"{trend['slope']:.4f}\",\n",
    "#     'R-squared': f\"{trend['r_squared']:.4f}\",\n",
    "#     'P-value': f\"{trend['p_value']:.4e}\"\n",
    "# }\n",
    "\n",
    "# findings_df = pd.DataFrame(list(findings.items()), columns=['Metric', 'Value'])\n",
    "# findings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Key Insights\n",
    "\n",
    "| Finding | Value | Confidence | Implication |\n",
    "|---------|-------|------------|-------------|\n",
    "| {Finding 1} | {Value} | {High/Medium/Low} | {What it means} |\n",
    "| {Finding 2} | {Value} | {High/Medium/Low} | {What it means} |\n",
    "| {Finding 3} | {Value} | {High/Medium/Low} | {What it means} |\n",
    "\n",
    "### 7.3 Limitations and Caveats\n",
    "\n",
    "- {Limitation 1}\n",
    "- {Limitation 2}\n",
    "- {Limitation 3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Export & Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXPORT SUMMARY DATA\n",
    "# =============================================================================\n",
    "\n",
    "# Export findings\n",
    "# findings_df.to_csv(DATA_PROCESSED / f'{EPISODE}_findings.csv', index=False)\n",
    "\n",
    "# Export as JSON for web integration\n",
    "# with open(DATA_PROCESSED / f'{EPISODE}_findings.json', 'w') as f:\n",
    "#     json.dump(findings, f, indent=2)\n",
    "\n",
    "print(f'\\n{\"=\"*60}')\n",
    "print(f'Analysis Complete: Episode {EPISODE}')\n",
    "print(f'{\"=\"*60}')\n",
    "print(f'\\nOutputs:')\n",
    "print(f'  Data: {DATA_PROCESSED}')\n",
    "print(f'  Figures: {VIZ_FIGURES}')\n",
    "print(f'  Interactive: {VIZ_INTERACTIVE}')\n",
    "print(f'\\nNext Steps:')\n",
    "print(f'  1. Review figures for article integration')\n",
    "print(f'  2. Update ARTICLE_{EPISODE}.md with findings')\n",
    "print(f'  3. Cross-check with methodology documentation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Notebook Metadata\n",
    "\n",
    "| Field | Value |\n",
    "|-------|-------|\n",
    "| **Episode** | {X.X} - {Episode Name} |\n",
    "| **Notebook** | {NN} - {Notebook Purpose} |\n",
    "| **Type** | {Article-Aligned / Novel Analysis} |\n",
    "| **Version** | 1.0.0 |\n",
    "| **Last Run** | {YYYY-MM-DD} |\n",
    "| **Python** | 3.11+ |\n",
    "| **Dependencies** | pandas, numpy, matplotlib, seaborn, plotly, scipy |\n",
    "\n",
    "---\n",
    "\n",
    "> **︻デ═─── ✦ ✦ ✦ | Aim Twice, Shoot Once!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
